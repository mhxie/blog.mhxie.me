[{"content":"BDP(Bandwidth delay product): bandwidth-delay product (BDP\u0026rsquo;s) worth of buffer, where bandwidth is the bottleneck link and delay is the round-trip time (RTT) between sender and destination.\nOptimization more on the sender part?\nClient-driven protocol eRPC is a datacenter remote procedure call (RPC) framework or say library that provides high performance RPC based on either lossy ethernet or lossless fabrics.\nBased on the high speed packet IO framework DPDK, the main design of eRPC lies on the following optimizations:\n(1) Zero-copy request processing: assuming the common case of lossless network, in client end, eRPC will not allow a TX queue with a reference to the request msgbuf when that request is being processed, which means there should not be any retransmitted packet in their assumption.\n(2) Preallocated responses: following (1), in server end, eRPC does not need to copy data from RX buffer ring to dynamically allocated application buffer called msgbuf but only using DMAed data whose headers are stripped in advance.\n(3) Multi-packet RQ: they came up with a BDP flow control that limit the number of in-flight packets based on the allowable BDP/packet size (e.g. MTU)\nCommon cases optimizations: (4) Rate limiter bypass: it will directly place the data to rx/tx buffer in userspace rather than rate limiter.\n(5) Congestion control (timely) bypass: based on the report showing that data centers are usually underutilized and uncongested, they intentionally omit the congestion control until\n(6) Batched RTT time stamp: timestamping overhead can hurt a lot because each call to rdtsc() cost 8ns when it comes to a scale of million-level. So they batched this call by sampling.\nSo basically, eRPC is a composition of optimization ideas with the assumption of lossless and uncongested situation. As a result, eRPC achieves up to 10 mpps for small RPC request or 75Gbps for large messages by using a single core. What\u0026rsquo;s more, the replication latency is as low as 5.5us which is even better than programmable hardware options.\nFuture directions: Statistical multiplexing for session credits\nDrawbacks:  eRPC is pretty much optimized for small RPC request, the throughput result is based on a packet as large as 8MB which is a ridiculous size in most of cases. This paper does not show any diagram of the performance what if the common case is not satisfied. They do not implement SACKs due to the engineering complexity. Bypassing the rate limiter is wired and inconvenient in terms of performance isolation and it is by no means a good choise from the perspective of virtualization.  ","permalink":"https://blog.mhxie.me/review/erpc_nsdi19/","summary":"BDP(Bandwidth delay product): bandwidth-delay product (BDP\u0026rsquo;s) worth of buffer, where bandwidth is the bottleneck link and delay is the round-trip time (RTT) between sender and destination.\nOptimization more on the sender part?\nClient-driven protocol eRPC is a datacenter remote procedure call (RPC) framework or say library that provides high performance RPC based on either lossy ethernet or lossless fabrics.\nBased on the high speed packet IO framework DPDK, the main design of eRPC lies on the following optimizations:","title":"eRPC Review - NSDI '19 "},{"content":"The Paper[1] presents a remote-flash-accessing system called ReFlex, which provides comparable performance to accessing local Flash. The authors point out that remote access to hard disks and remote access to Flash using RDMA (Remote Direct Memory Access) are two common ways to offer flexibility and efficiency in a data center. However, they prove these existing approaches are facing two critical problems: the first is how to tradeoff between performance and cost, while the second is how to provide predictable performance without interferences. Thus they design this system to avoid the problems current systems may raise while still meeting the performance expectations.\nReFlex uses a tightly integrated data plane architecture to provide low latency and high throughput access to remote Flash. In the first place, the authors exploit the virtualization features in the hardware, though it is a software system, to transfer data and requests without copying them. Also, the polling-based execution model eliminates the interruptions of process. Thanks to the novel QoS scheduler, ReFlex serves different types of tenants to enforce SLOs (Service-Level Objectives), even for different data streams. By these means, the authors state that ReFlex is able to deal with thousands of tenants and network connections due to its high utilization to CPU cores.\nThe architecture of ReFlex is Client-Server model: server is responsible for executing the models mentioned above and clients are written for applications to access the servers. Moreover, the authors re-design the control plane that runs on every ReFlex server to balance the loads. ReFlex outreaches its competitors on tail latency, request/response throughput and CPU resources utilization, with well-behaved QoS scheduling and tenant isolations. Therefore, ReFlex can serve up to 850K IOPS per core over TCP/IP networking, with merely 21us addition over direct access to local Flash.\nReference:\n[1] Klimovic, A., Litz, H., \u0026amp; Kozyrakis, C. (2017). Reflex: remote flash â‰ˆ local flash. ACM SIGOPS Operating Systems Review, 51(2), 345-359.\n","permalink":"https://blog.mhxie.me/review/reflex_asplos17/","summary":"The Paper[1] presents a remote-flash-accessing system called ReFlex, which provides comparable performance to accessing local Flash. The authors point out that remote access to hard disks and remote access to Flash using RDMA (Remote Direct Memory Access) are two common ways to offer flexibility and efficiency in a data center. However, they prove these existing approaches are facing two critical problems: the first is how to tradeoff between performance and cost, while the second is how to provide predictable performance without interferences.","title":"ReFlex Review - ASPLOS '17 "},{"content":"My name is Minghao Xie. I am a third-year computer engineering Ph.D. student at Baskin School of Engineering, UC Santa Cruz. Before, I got my B.E. degree in Computer Science from Sichuan University, China.\nI am fortunate to be advised by Chen Qian and Heiner Litz. My research interests revolve around computer networks and systems. My current work focuses on flash storage disaggregation within data centers as part of the Center for Research in Storage Systems (CRSS) at UCSC. I enjoy building real systems that are scalable, deliver high performance and which are easy to use.\n","permalink":"https://blog.mhxie.me/about/","summary":"About","title":"About me"}]