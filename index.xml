<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Minghao&#39;s Personal Blog</title>
    <link>https://blog.mhxie.me/</link>
    <description>Recent content on Minghao&#39;s Personal Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Apr 2021 23:07:37 +0000</lastBuildDate><atom:link href="https://blog.mhxie.me/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Silo Review - SIGCOMM &#39;15</title>
      <link>https://blog.mhxie.me/review/silo_sigcomm15/</link>
      <pubDate>Fri, 16 Apr 2021 23:07:37 +0000</pubDate>
      
      <guid>https://blog.mhxie.me/review/silo_sigcomm15/</guid>
      <description>Summary This paper [1] presents Silo, a system that can gurantee both latency and throughput service level objectives (SLOs) in multi-tenant data centers.
Design Goals  guaranteed bandwidth; guaranteed packet delay; guaranteed burst allowance;  Challenges    delay is an additive end-to-end property
  queueing delay is the marjor factor along the critical path and it is hard to precisely enforce indepedent flows on all networking knobs   guaranteed packet delay is at odds with the guaranteed burst requirement</description>
    </item>
    
    <item>
      <title>Hoard Review - ASPLOS IX</title>
      <link>https://blog.mhxie.me/review/hoard_asplosix/</link>
      <pubDate>Wed, 22 May 2019 07:31:37 +0000</pubDate>
      
      <guid>https://blog.mhxie.me/review/hoard_asplosix/</guid>
      <description>Summary Hoard is a concurrent memory allocator algorithm that achieves both a performance close to the uniprocessor allocator and a low memory fragmentation rate. False sharing and fragmentation are two showing problems that degrade the performance of concurrent memory allocators. Allocator may actively or passively cause false sharing by splitting a cache line to different processes in turn or by reusing the free pieces. On the other hand, internal and external fragmentation may cause unbounded memory blowup.</description>
    </item>
    
    <item>
      <title>eRPC Review - NSDI &#39;19 </title>
      <link>https://blog.mhxie.me/review/erpc_nsdi19/</link>
      <pubDate>Sat, 13 Apr 2019 07:35:40 +0000</pubDate>
      
      <guid>https://blog.mhxie.me/review/erpc_nsdi19/</guid>
      <description>BDP(Bandwidth delay product): bandwidth-delay product (BDP&amp;rsquo;s) worth of buffer, where bandwidth is the bottleneck link and delay is the round-trip time (RTT) between sender and destination.
Optimization more on the sender part?
Client-driven protocol eRPC is a datacenter remote procedure call (RPC) framework or say library that provides high performance RPC based on either lossy ethernet or lossless fabrics.
Based on the high speed packet IO framework DPDK, the main design of eRPC lies on the following optimizations:</description>
    </item>
    
    <item>
      <title>Crail Review - IEEE Data Eng. Bull. Vol 40</title>
      <link>https://blog.mhxie.me/review/crail/</link>
      <pubDate>Sun, 02 Dec 2018 07:31:37 +0000</pubDate>
      
      <guid>https://blog.mhxie.me/review/crail/</guid>
      <description>The performance of networking and storage hardware has developed rapidly in recent years. Emerging new interfaces like RDMA and NVMe make user-level hardware access and asynchronous I/O possible, allowing upper applications to take full advantages of these high-performance hardware. However, the authors of Crail (Stuedi, P. et al., 2017) point out that most of the recent applications are too low-brewed and too focused on serving particular workloads to satisfy general task requirement.</description>
    </item>
    
    <item>
      <title>LHD Review - NSDI &#39;18</title>
      <link>https://blog.mhxie.me/review/lhd_nsdi18/</link>
      <pubDate>Sun, 02 Dec 2018 07:31:37 +0000</pubDate>
      
      <guid>https://blog.mhxie.me/review/lhd_nsdi18/</guid>
      <description>Beckmann, N., Chen, H., &amp;amp; Cidon, A. (2018, April). LHD: Improving Cache Hit Rate by Maximizing Hit Density. In 15th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} 18). USENIX} Association.
Least hit density (LHD) [1] is a brand-new cache replacement algorithm designed for key-value caches. An improvement to the cache hit rate of current distributed, in-memory key-value caches has shown more and more importance in demand of latency sensitive applications recently.</description>
    </item>
    
    <item>
      <title>ReFlex Review - ASPLOS &#39;17 </title>
      <link>https://blog.mhxie.me/review/reflex_asplos17/</link>
      <pubDate>Sun, 02 Dec 2018 07:31:37 +0000</pubDate>
      
      <guid>https://blog.mhxie.me/review/reflex_asplos17/</guid>
      <description>The Paper[1] presents a remote-flash-accessing system called ReFlex, which provides comparable performance to accessing local Flash. The authors point out that remote access to hard disks and remote access to Flash using RDMA (Remote Direct Memory Access) are two common ways to offer flexibility and efficiency in a data center. However, they prove these existing approaches are facing two critical problems: the first is how to tradeoff between performance and cost, while the second is how to provide predictable performance without interferences.</description>
    </item>
    
    <item>
      <title>About me</title>
      <link>https://blog.mhxie.me/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://blog.mhxie.me/about/</guid>
      <description>About</description>
    </item>
    
    
    
  </channel>
</rss>
